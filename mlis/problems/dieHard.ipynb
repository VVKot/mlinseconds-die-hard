{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dieHard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IuViXILkHfV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Die Hard\n",
        "\n",
        "There are 2 functions defined from input. One easy one and one hard one.\n",
        "\n",
        "On training data easy and hard functions produce same result and on\n",
        "test data you need to predict hard function."
      ]
    },
    {
      "metadata": {
        "id": "a7nQBNjiHoZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Copy auxiliary files from GitHub "
      ]
    },
    {
      "metadata": {
        "id": "zY6IVIQ9H3vP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm gridsearch.py solutionmanager.py speedtest.py\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-die-hard/master/mlis/utils/gridsearch.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-die-hard/master/mlis/utils/solutionmanager.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-die-hard/master/mlis/utils/speedtest.py -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOfJMXKsILMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries and utils"
      ]
    },
    {
      "metadata": {
        "id": "h0u8cfq_Kb7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboard tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYcFLIINIOrH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import solutionmanager as sm\n",
        "from gridsearch import GridSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyZFLqciJbWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check whether CUDA is available"
      ]
    },
    {
      "metadata": {
        "id": "FHGP0tazJeCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQ6_CBWKIvO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create neural network"
      ]
    },
    {
      "metadata": {
        "id": "T9hEryV9I4Xv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SolutionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, solution):\n",
        "        super(SolutionModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        sm.SolutionManager.print_hint(\"Hint[1]: NN usually learn easiest function, you need to learn hard one\")\n",
        "        self.hidden_size = 10\n",
        "        self.linear1 = nn.Linear(input_size, self.hidden_size)\n",
        "        self.linear2 = nn.Linear(self.hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = self.linear2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "    def calc_loss(self, output, target):\n",
        "        loss = ((output-target)**2).sum()\n",
        "        return loss\n",
        "\n",
        "    def calc_predict(self, output):\n",
        "        predict = output.round()\n",
        "        return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06EEkpYVI5M7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create class to store hyper parameters. Implement grid search"
      ]
    },
    {
      "metadata": {
        "id": "Jgtm0ny5JI8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Solution():\n",
        "    def __init__(self):\n",
        "        self.best_step = 1000\n",
        "        self.activations = {\n",
        "            'sigmoid': nn.Sigmoid(),\n",
        "            'relu': nn.ReLU(),\n",
        "            'rrelu0103': nn.RReLU(0.1, 0.3),\n",
        "            'elu': nn.ELU(),\n",
        "            'selu': nn.SELU(),\n",
        "            'leakyrelu01': nn.LeakyReLU(0.1)\n",
        "        }\n",
        "        self.learning_rate = 0.8\n",
        "        self.momentum = 0.9\n",
        "        self.hidden_size = 45\n",
        "        self.layers_number = 5\n",
        "        self.activation_hidden = 'relu'\n",
        "        self.activation_output = 'sigmoid'\n",
        "        self.do_batch_norm = True\n",
        "        self.sols = {}\n",
        "        self.solsSum = {}\n",
        "        self.random = 0\n",
        "        self.random_grid = [_ for _ in range(10)]\n",
        "        self.layers_number_grid = [5, 6, 7, 8]\n",
        "        self.hidden_size_grid = [20, 25, 28, 30, 32, 35, 38, 40, 45]\n",
        "#         self.momentum_grid = [0.0, 0.3, 0.5, 0.8, 0.9]\n",
        "        self.learning_rate_grid = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.5]\n",
        "        self.activation_hidden_grid = list(self.activations.keys())\n",
        "#         self.activation_output_grid = list(self.activations.keys())\n",
        "        self.grid_search = GridSearch(self)\n",
        "        self.grid_search.set_enabled(False)\n",
        "\n",
        "    def create_model(self, input_size, output_size):\n",
        "        return SolutionModel(input_size, output_size, self)\n",
        "\n",
        "    def get_key(self):\n",
        "        return \"{}_{}_{}_{}_{}_{}_{}\".format(self.learning_rate, self.momentum, self.hidden_size, self.activation_hidden, self.activation_output, self.do_batch_norm, \"{0:03d}\".format(self.layers_number));\n",
        "\n",
        "    # Return number of steps used\n",
        "    def train_model(self, model, train_data, train_target, context):\n",
        "        key = self.get_key()\n",
        "        if key in self.sols and self.sols[key] == -1:\n",
        "            return\n",
        "        step = 0\n",
        "        model.to(device)\n",
        "        # Put model in train mode\n",
        "        model.train()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
        "        while True:\n",
        "            time_left = context.get_timer().get_time_left()\n",
        "            # No more time left, stop training\n",
        "            if time_left < 0.1:\n",
        "                break\n",
        "            data = train_data\n",
        "            target = train_target\n",
        "            # model.parameters()...gradient set to zero\n",
        "            optimizer.zero_grad()\n",
        "            # evaluate model => model.forward(data)\n",
        "            output = model(data)\n",
        "            # if x < 0.5 predict 0 else predict 1\n",
        "            predict = model.calc_predict(output)\n",
        "            # Number of correct predictions\n",
        "            correct = predict.eq(target.view_as(predict)).long().sum().item()\n",
        "            # Total number of needed predictions\n",
        "            total = predict.view(-1).size(0)\n",
        "#             if correct == total or (self.grid_search.enabled and step > 1000):\n",
        "#                 if not key in self.sols:\n",
        "#                     loss = model.calc_loss(output, target)\n",
        "#                     self.sols[key] = 0\n",
        "#                     self.solsSum[key] = 0\n",
        "#                     self.sols[key] += 1\n",
        "#                     self.solsSum[key] += step\n",
        "#                 if correct == total:\n",
        "#                     self.print_stats(step, loss, correct, total, model)\n",
        "#                     print('{:.4f}'.format(float(self.solsSum[key])/self.sols[key]))\n",
        "#                 break\n",
        "            # calculate loss\n",
        "            loss = model.calc_loss(output, target)\n",
        "            # calculate deriviative of model.forward() and put it in model.parameters()...gradient\n",
        "            loss.backward()\n",
        "            # print progress of the learning\n",
        "            # update model: model.parameters() -= lr * gradient\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "        return step\n",
        "    \n",
        "    def print_stats(self, step, loss, correct, total, model):\n",
        "        print(\"LR={}, Momentum={}, HS={}, Number of layers={}, ActivOut={}, Step = {} Prediction = {}/{} Error = {}\".format(model.solution.learning_rate, model.solution.momentum,\n",
        "                                                                                                              model.hidden_size, model.layers_number, model.activation_hidden, step, correct, total, loss.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKLqM7yTJMQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create class for data generation"
      ]
    },
    {
      "metadata": {
        "id": "R4LjeldMJOKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Limits:\n",
        "    def __init__(self):\n",
        "        self.time_limit = 2.0\n",
        "        self.size_limit = 1000000\n",
        "        self.test_limit = 0.75\n",
        "\n",
        "class DataProvider:\n",
        "    def __init__(self):\n",
        "        self.number_of_cases = 20\n",
        "\n",
        "    def full_func(self, input_size):\n",
        "        while True:\n",
        "            table = torch.ByteTensor(1<<input_size).random_(0, 2)\n",
        "            vals = torch.ByteTensor(input_size, 2).zero_()\n",
        "            depend_count = 0\n",
        "            for i in range(input_size):\n",
        "                for ind in range(1<<input_size):\n",
        "                    if table[ind].item() != table[ind^(1<<i)].item():\n",
        "                        depend_count += 1\n",
        "                        break\n",
        "            if depend_count == input_size:\n",
        "                return table\n",
        "\n",
        "    def tensor_to_int(self, tensor):\n",
        "        tensor = tensor.view(-1)\n",
        "        res = 0\n",
        "        for x in tensor:\n",
        "            res = (res<<1)+x.item()\n",
        "        return res\n",
        "\n",
        "    def int_to_tensor(self, ind, tensor):\n",
        "        for i in range(tensor.size(0)):\n",
        "            tensor[i] = (ind >> i)&1\n",
        "\n",
        "    def create_data(self, seed, easy_table, hard_table, easy_input_size, hard_input_size, easy_correct):\n",
        "        input_size = easy_input_size + hard_input_size\n",
        "        data_size = 1 << input_size\n",
        "        data = torch.ByteTensor(data_size, input_size)\n",
        "        target = torch.ByteTensor(data_size, 1)\n",
        "        count = 0\n",
        "        for ind in range(data_size):\n",
        "            self.int_to_tensor(ind, data[count])\n",
        "            easy_ind = ind & ((1 << easy_input_size)-1)\n",
        "            hard_ind = ind >> easy_input_size\n",
        "            easy_value = easy_table[easy_ind].item()\n",
        "            hard_value = hard_table[hard_ind].item()\n",
        "            target[count, 0] = hard_value\n",
        "            if not easy_correct or easy_value == hard_value:\n",
        "                count += 1\n",
        "        data = data[:count,:]\n",
        "        target = target[:count,:]\n",
        "        perm = torch.randperm(count)\n",
        "        data = data[perm]\n",
        "        target = target[perm]\n",
        "        return (data.float().to(device), target.float().to(device))\n",
        "\n",
        "    def create_case_data(self, case):\n",
        "        easy_input_size = 2\n",
        "        hard_input_size = 6\n",
        "\n",
        "        random.seed(case)\n",
        "        torch.manual_seed(case)\n",
        "        easy_table = self.full_func(easy_input_size)\n",
        "        hard_table = self.full_func(hard_input_size)\n",
        "        train_data, train_target = self.create_data(case, easy_table, hard_table, easy_input_size, hard_input_size, True)\n",
        "        test_data, test_target = self.create_data(case, easy_table, hard_table, easy_input_size, hard_input_size, False)\n",
        "        perm = torch.randperm(train_data.size(1))\n",
        "        train_data = train_data[:,perm]\n",
        "        test_data = test_data[:,perm]\n",
        "        return sm.CaseData(case, Limits(), (train_data, train_target), (test_data, test_target)).set_description(\"Easy {} inputs and hard {} inputs\".format(easy_input_size, hard_input_size))\n",
        "      \n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.max_samples = 10000\n",
        "\n",
        "    def get_data_provider(self):\n",
        "        return DataProvider()\n",
        "\n",
        "    def get_solution(self):\n",
        "        return Solution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWLKl-o2kCmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evalute the model"
      ]
    },
    {
      "metadata": {
        "id": "ZD7mdYqO88hr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sm.SolutionManager(Config()).run(case_number=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}